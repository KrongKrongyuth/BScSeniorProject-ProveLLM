from typing import List, Literal
from typing_extensions import TypedDict
from pydantic import BaseModel, Field

from langchain_ollama import ChatOllama
from langchain.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, START, END

from model import get_response
from tools import theorem_retriever, wiki_search

from dotenv import load_dotenv; load_dotenv()

class RouteQuery(BaseModel):
    """Route a user query to the most relevant datasource."""
    
    datasource: Literal['theorem_db', 'wikipedia_search'] = Field(
        ...,
        description="Given a user question choose which datasource would be most relevant for answering their question"
    )

class GraphState(TypedDict):
    """
    Tracking the state of our graph
    
    Attributes:
        question: question or query from user
        result: result generate from LLM
    """
    
    question: str
    documents: List[str]
    result: str

def generate(state:GraphState):
    """
    Get the result, generated by LLM
    """
    return {'result': get_response(state['question'], state['documents'])}

def build_graph(state:GraphState = GraphState, get_graph_image:bool=True):
    workflow = StateGraph(state)
    
    # Create node for our graph
    workflow.add_node('chatbot', generate)
    workflow.add_node('theorem_db', retrieve)   # Retrieve the data from theorem db
    workflow.add_node('wikipedia_search', wiki)      # Search using Wikipedia
    
    # Create edges
    workflow.add_conditional_edges(
        START,
        get_router_response,
        {
            'wikipedia_search': 'wikipedia_search',
            'theorem_db': 'theorem_db'
        }
    )
    workflow.add_edge('wikipedia_search', 'chatbot')
    workflow.add_edge('theorem_db', 'chatbot')
    workflow.add_edge('chatbot', END)
    
    graph = workflow.compile()
    
    if get_graph_image:
        graph.get_graph().print_ascii()
    
    return graph

def retrieve(state:GraphState = GraphState):
    """
    Retrieve the documents from theorem database
    """
    
    question = state['question']
    retrieved_docs = theorem_retriever.retrieve_docs(question)
    
    return {'documents': retrieved_docs, 'question': question}

def wiki(state:GraphState = GraphState):
    """
    Search for the wikipedia
    """
    
    question = state['question']
    wiki_docs = wiki_search.get_wiki_docs(question)
    
    return {'documents': wiki_docs, 'question': question}

def get_router_response(state:GraphState = GraphState, route:RouteQuery = RouteQuery):
    sturctured_llm = ChatOllama(model='llama3.1:8b').with_structured_output(route)
    system_prompt = """You are an expert at rounting a user question to a theorem_db or wikipedia_search.
    The theorem_db contains mathematical theorem that you can use as a refference for contribute a prove for user question.
    ortherwise you can use wikipedia_search
    """
    
    route_prompt = ChatPromptTemplate.from_messages(
        [
            ('system', system_prompt),
            ('human', "{question}")
        ]
    )
    
    question = state['question']
    router_chain = route_prompt | sturctured_llm
    source = router_chain.invoke({'question': question})
    
    if source.datasource == 'wikipedia_search':
        return 'wikipedia_search'
    elif source.datasource == 'theorem_db':
        return 'theorem_db'

if __name__ == "__main__":
    graph = build_graph()